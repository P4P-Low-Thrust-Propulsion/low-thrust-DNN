{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:44:59.440544Z",
     "start_time": "2024-04-30T01:44:59.375143Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "scaler = MinMaxScaler()\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "\n",
    "df_Features = df.iloc[:, :7]\n",
    "df_Labels   = df.iloc[:, -1]\n",
    "\n",
    "data_Features = df_Features.values\n",
    "data_Labels = df_Labels.values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# Fit and transform the features\n",
    "\n",
    "\n",
    "\n",
    "#X = torch.from_numpy(X).type(torch.float)\n",
    "#y = torch.from_numpy(y).type(torch.float)\n",
    "#tensor_Features = torch.tensor(data_Features, dtype=torch.float32)\n",
    "#tensor_Labels   = torch.tensor(data_Labels  , dtype=torch.float32)\n",
    "X = torch.from_numpy(data_Features).type(torch.float)\n",
    "y = torch.from_numpy(data_Labels).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "len(X_train),len(X_test),len(y_train),len(y_test)\n",
    "y_train = torch.unsqueeze(y_train, dim=1)\n",
    "y_test = torch.unsqueeze(y_test, dim=1)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:23:59.527413Z",
     "start_time": "2024-04-30T01:23:59.518033Z"
    }
   },
   "id": "eee421c5d18a5d4e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. Construct a model class that subclasses nn.Module\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model_0v1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Linear(in_features=7,out_features=32)\n",
    "        self.layer2=nn.Linear(in_features=32,out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #return self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))\n",
    "        return self.layer2(self.relu(self.layer1(x)))\n",
    "\n",
    "torch.manual_seed(42)\n",
    "#create an instance of the mdoel \n",
    "model_01 = Model_0v1()\n",
    "model_01.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:24:00.224443Z",
     "start_time": "2024-04-30T01:24:00.209313Z"
    }
   },
   "id": "f9acf03ac04cefbe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_01.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:15:13.779833Z",
     "start_time": "2024-04-30T01:15:13.774125Z"
    }
   },
   "id": "4113756b0bf1afc9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#train the model, \n",
    "\n",
    "#the whole idea is to move the red dots to the green, unknown pararemeters to known parameters\n",
    "#loss function \n",
    "#optomizer \n",
    "\n",
    "\n",
    "# setting up a loss function \n",
    "loss_fn=nn.MSELoss()\n",
    "\n",
    "# setting up a optomizer \n",
    "optomizer = torch.optim.SGD(params = model_01.parameters(),\n",
    "                            lr = 0.05) #lr = learning rate\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:24:07.216337Z",
     "start_time": "2024-04-30T01:24:07.211223Z"
    }
   },
   "id": "8066d27498f5d119",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "epochs = 1000\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "losses = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_01.train() \n",
    "    # 1 forward pass \n",
    "    y_preds = model_01(X_train)\n",
    "    # 2 calculate the loss \n",
    "    loss = loss_fn(y_preds,y_train)\n",
    "    losses.append(loss.item())\n",
    "    # 3 optomizer zero grad \n",
    "    optomizer.zero_grad()\n",
    "    # 4 perfrom back propogation on the loss with respect to the parameters of the model \n",
    "    loss.backward()\n",
    "    # 5. step the optimizer (perform gradeint descent )\n",
    "    optomizer.step() # by deful how the optimzer changes will acculumate through the loop so we have to zero them above in step 3\n",
    "    #TESTING\n",
    "    model_01.eval() #tunrs off diffrence setting sin th emodel not needed evaluating/testing\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        # 1. forward \n",
    "        test_pred = model_01(X_test)\n",
    "        #2. lest \n",
    "        test_loss = loss_fn(test_pred,y_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "    \n",
    "\n",
    "    if epoch%100==0:\n",
    "        #print(f\"Loss: {y_preds}\")\n",
    "        print(f\"Epoch: {epoch} | Test: {loss} | Test loss: {test_loss}\")\n",
    "\n",
    "    \n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:15:05.649470Z",
     "start_time": "2024-04-30T01:15:05.260972Z"
    }
   },
   "id": "9dc24da78009a5c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_01.train() \n",
    "    # 1 forward pass \n",
    "y_preds = model_01(X_train)\n",
    "    # 2 calculate the loss \n",
    "loss = loss_fn(y_preds,y_train)\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:22:27.818798Z",
     "start_time": "2024-04-30T01:22:27.794221Z"
    }
   },
   "id": "c0ea3b5e29a0b2cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:22:28.892604Z",
     "start_time": "2024-04-30T01:22:28.578125Z"
    }
   },
   "id": "fd3bf5724f6b502c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_01.train() \n",
    "    # 1 forward pass \n",
    "y_preds = model_01(X_train)\n",
    "loss = loss_fn(y_preds,y_train)\n",
    "loss\n",
    "optomizer.zero_grad()\n",
    "    # 4 perfrom back propogation on the loss with respect to the parameters of the model \n",
    "loss.backward()\n",
    "    # 5. step the optimizer (perform gradeint descent )\n",
    "optomizer.step() # by deful how the optimzer changes will acculumate through the loop so we have to zero them above in step 3\n",
    "    #TESTING\n",
    "model_01.eval() #tunrs off diffrence setting sin th emodel not needed evaluating/testing"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:23:31.191516Z",
     "start_time": "2024-04-30T01:23:31.078787Z"
    }
   },
   "id": "4daa32391f922176",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_preds = model_01(X_train)\n",
    "loss = loss_fn(y_preds,y_train)\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:24:31.579188Z",
     "start_time": "2024-04-30T01:24:31.575041Z"
    }
   },
   "id": "e40870ffb4de06ec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "optomizer.zero_grad()\n",
    "    # 4 perfrom back propogation on the loss with respect to the parameters of the model \n",
    "loss.backward()\n",
    "    # 5. step the optimizer (perform gradeint descent )\n",
    "optomizer.step() # by deful how the optimzer changes will acculumate through the loop so we have to zero them above in step 3\n",
    "    #TESTING\n",
    "model_01.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:24:28.639417Z",
     "start_time": "2024-04-30T01:24:28.621116Z"
    }
   },
   "id": "45cc170c8aa941d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_Features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:37:56.919236Z",
     "start_time": "2024-04-30T01:37:56.886158Z"
    }
   },
   "id": "bac9b5d811e8dc50",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_Features_Scaled = scaler.fit_transform(df_Features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:38:16.740749Z",
     "start_time": "2024-04-30T01:38:16.721504Z"
    }
   },
   "id": "5dae51e9ba2060eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:48:29.838254Z",
     "start_time": "2024-04-30T01:48:29.834468Z"
    }
   },
   "id": "c975d02d55e94ee1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_unscaled = pd.read_csv('dataset.csv')\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df_unscaled)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:55:39.800270Z",
     "start_time": "2024-04-30T01:55:39.777499Z"
    }
   },
   "id": "e7d9b5dc989b892b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:55:47.689519Z",
     "start_time": "2024-04-30T01:55:47.680868Z"
    }
   },
   "id": "5101407b7e9e06ec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_scaled = df_scaled.rename(columns={'0': 'new_label'})\n",
    "#df_Features = df.iloc[:, :7]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T01:58:52.179302Z",
     "start_time": "2024-04-30T01:58:52.132549Z"
    }
   },
   "id": "a431d62357f7ea15",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51e988c1d3be2ce2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
