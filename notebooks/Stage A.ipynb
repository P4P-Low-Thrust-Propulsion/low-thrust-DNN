{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import time \n",
    "from IPython import display\n",
    "\n",
    "df = pd.read_csv('data_generation/data/transfer_data.csv')\n",
    "scaler = MinMaxScaler()\n",
    "# Fit the scaler to your data (optional, depending on the scaler)\n",
    "scaler.fit(df)\n",
    "\n",
    "# Transform the data using the fitted scaler and keep it as a DataFrame\n",
    "df = pd.DataFrame(scaler.transform(df), columns=df.columns)\n",
    "\n",
    "\n",
    "df_Features = df.iloc[:, :4]\n",
    "df_Labels = df.iloc[:, -3:]\n",
    "\n",
    "data_Features = df_Features.values\n",
    "data_Labels = df_Labels.values\n",
    "\n",
    "# Fit and transform the features\n",
    "X = torch.from_numpy(data_Features).type(torch.float)\n",
    "y = torch.from_numpy(data_Labels).type(torch.float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### CHEcking state of GPU \n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "len(X_train),len(X_test),len(y_train),len(y_test)\n",
    "#y_train = torch.unsqueeze(y_train, dim=1)\n",
    "#y_test = torch.unsqueeze(y_test, dim=1)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eee421c5d18a5d4e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 1. Construct a model class that subclasses nn.Module\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model_0v1(nn.Module):\n",
    "    n = 150\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Linear(in_features=4,out_features=n)\n",
    "        self.layer2=nn.Linear(in_features=n,out_features=n)\n",
    "        self.layer3=nn.Linear(in_features=n,out_features=n)\n",
    "        self.layer4=nn.Linear(in_features=n,out_features=3)\n",
    "        self.relu = nn.Softshrink()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #return self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))\n",
    "        return self.layer4(self.relu(self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))))\n",
    "\n",
    "torch.manual_seed(42)\n",
    "#create an instance of the mdoel \n",
    "model_01 = Model_0v1()\n",
    "model_01.state_dict()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9acf03ac04cefbe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Model on device:\\n{next(model_01.parameters()).device}\")\n",
    "X_test.to(device)\n",
    "print(f\"DATA on device:\\n{X_test.device}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4113756b0bf1afc9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#train the model, \n",
    "\n",
    "#the whole idea is to move the red dots to the green, unknown pararemeters to known parameters\n",
    "#loss function \n",
    "#optomizer \n",
    "\n",
    "\n",
    "# setting up a loss function \n",
    "loss_fn=nn.MSELoss()\n",
    "\n",
    "# setting up a optomizer \n",
    "optomizer = torch.optim.SGD(params = model_01.parameters(),\n",
    "                            lr = 0.05) #lr = learning rate\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8066d27498f5d119",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already on CPU\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# Assuming model_01, loss_fn, optimizer are already defined\n",
    "# Move model and optimizer to GPU\n",
    "model_01 = model_01.to(device)\n",
    "#optimizer = optomizer.to(device)\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 10000\n",
    "\n",
    "# Lists to store losses\n",
    "losses = []\n",
    "test_losses = []\n",
    "epochs_array = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    epochs_array.append(epoch)\n",
    "    model_01.train() \n",
    "    \n",
    "    # Forward pass\n",
    "    y_preds = model_01(X_train)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = loss_fn(y_preds, y_train)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Zero gradients\n",
    "    optomizer.zero_grad()\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step the optimizer (perform gradient descent)\n",
    "    optomizer.step()\n",
    "    \n",
    "    # Testing\n",
    "    model_01.eval()\n",
    "    \n",
    "    with torch.no_grad():  # Ensure no gradients are computed\n",
    "        # Forward pass for testing\n",
    "        test_preds = model_01(X_test)\n",
    "        \n",
    "        # Calculate test loss\n",
    "        test_loss = loss_fn(test_preds, y_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Status: {epoch * 100 / epochs}% | Epoch: {epoch} | Training Loss: {loss:.8f} | Test Loss: {test_loss:.8f}\")\n",
    "\n",
    "\n",
    "print(f\"Training took : {time.time()-start_time}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.plot(epochs_array, losses, label='Training Loss')\n",
    "plt.plot(epochs_array, test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dc24da78009a5c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "##making estimations \n",
    "model_01.eval() #tunrs off diffrence setting sin th emodel not needed evaluating/testing\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_01(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3fc78ad33a093a8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "##unscale the y_test and y_preds \n",
    "def unscale(scaled_value, i):\n",
    "    unscaled_value = scaled_value * (scaler.data_max_[i] - scaler.data_min_[i]) + (scaler.data_min_[i])\n",
    "    return unscaled_value\n",
    "\n",
    "df_result_ytest_scaled = pd.concat([pd.DataFrame(X_test.numpy()), pd.DataFrame(y_test.numpy())], ignore_index=True, axis = 'columns')\n",
    "df_result_ypreds_scaled = pd.concat([pd.DataFrame(X_test.numpy()), pd.DataFrame(y_preds.numpy())], ignore_index=True, axis = 'columns')\n",
    "\n",
    "# Apply to unscale function to each column of inputs array\n",
    "df_result_ytest = pd.DataFrame()\n",
    "df_result_ypreds = pd.DataFrame()\n",
    "\n",
    "for column in df_result_ytest_scaled.columns:\n",
    "   df_result_ytest[column] = unscale(df_result_ytest_scaled[column], column)\n",
    "   df_result_ypreds[column] = unscale(df_result_ypreds_scaled[column], column)\n",
    "df_result_ytest, df_result_ypreds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a889eaed5a7de49c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.scatter(epochs_array[:n], np.linalg.norm(df_result_ytest.iloc[:, -3:], axis=1)[:n], c='green',  label='y_test')\n",
    "plt.scatter(epochs_array[:n], np.linalg.norm(df_result_ypreds.iloc[:, -3:], axis=1)[:n], c='blue', label='y_preds')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Magnitude of velocity [km/s]')\n",
    "plt.title('Scatter Plot of Magnitudes Scaled back')\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ac2986c5e223f22",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.scatter(epochs_array[:n], np.linalg.norm(df_result_ytest_scaled, axis=1)[:n], c='green', label='y_test')\n",
    "plt.scatter(epochs_array[:n], np.linalg.norm(df_result_ypreds_scaled, axis=1)[:n], c='blue', label='y_preds')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Magnitude of velocity [km/s]')\n",
    "plt.title('Scatter Plot of Magnitudes unscaled')\n",
    "plt.legend()\n",
    "\n",
    "save"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17f39b80b2d53cc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#saving a model in pytorch\n",
    "\n",
    "from pathlib    import Path \n",
    "# create models directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "#create model save path \n",
    "MODEL_NAME= \"LeakyRelu.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
    "print(f\"Saving model to : {MODEL_SAVE_PATH}\") \n",
    "\n",
    "#3. SAVE THE MODEL SAVE DICT \n",
    "torch.save(obj=model_01.state_dict(),f=MODEL_SAVE_PATH)\n",
    "\n",
    "## Loading the model of just the state dict \n",
    "#new instance of the linear regression model class \n",
    "#loaded_model_0 = LinearRegressionModel()\n",
    "#load the saved state_dict of model_0 into the new instance \n",
    "#loaded_model_0.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "#print(loaded_model_0.state_dict())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee78a2d20df8aaef",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
